{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c66621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer1.ogg',\n",
       " 'customer2.ogg',\n",
       " 'file1.mp3',\n",
       " 'file2.flac',\n",
       " 'file3.flac',\n",
       " 'file4.flac',\n",
       " 'file5.ogg',\n",
       " 'file6.ogg',\n",
       " 'file7.ogg',\n",
       " 'file8.mp4',\n",
       " 'file9.ogg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import OS Module\n",
    "import os\n",
    "\n",
    "#Check Audio Files Folder\n",
    "os.listdir(\"ipFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae57f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mujhe kuch khane ko de do'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#Import First File and Convert to .wav\n",
    "file1 = AudioSegment.from_file(\"ipFiles/file1.mp3\")\n",
    "file1.export(\"exportedWav.file1.wav\", format=\"wav\")\n",
    "\n",
    "#Transcribe file1\n",
    "recognizer = sr.Recognizer()\n",
    "file1_file = sr.AudioFile(\"exportedWav/file1.wav\")\n",
    "with file1_file as src:\n",
    "    file1_audio = recognizer.record(file1_file)\n",
    "recognizer.recognize_google(file1_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09839212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting file1.mp3 to exportedWav/file1.wav... (completed)\n"
     ]
    }
   ],
   "source": [
    "#File Format Conversion Function\n",
    "#===============================\n",
    "\n",
    "def convertToWav(filename):\n",
    "    #Import Audio File\n",
    "    file = AudioSegment.from_file(filename)\n",
    "    #Create New Filename\n",
    "    filename = filename.split(\"/\")[1] #to remove parent directory\n",
    "    newFilename = \"exportedWav/\" + filename.split(\".\")[0] + \".wav\"\n",
    "    #Export file as .wav\n",
    "    file.export(newFilename, format=\"wav\")\n",
    "    print(f\"Converting {filename} to {newFilename}... (completed)\")\n",
    "    \n",
    "convertToWav(\"ipFiles/file1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3106ab67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exportedWav/file1.wav Channels: 2\n",
      "exportedWav/file1.wav Sample Width: 2\n",
      "exportedWav/file1.wav Frame Rate: 44100\n",
      "exportedWav/file1.wav Frame Count: 137088.0\n",
      "exportedWav/file1.wav Frame Width: 4\n",
      "exportedWav/file1.wav Length in ms: 3109\n"
     ]
    }
   ],
   "source": [
    "#Attribute Showing Function\n",
    "#==========================\n",
    "\n",
    "def showPydubStats(filename):\n",
    "    #Create AudioSegment Instance\n",
    "    file = AudioSegment.from_file(filename)\n",
    "    #Print Audio Attributes\n",
    "    print(f\"{filename} Channels: {file.channels}\")\n",
    "    print(f\"{filename} Sample Width: {file.sample_width}\")\n",
    "    print(f\"{filename} Frame Rate: {file.frame_rate}\")\n",
    "    print(f\"{filename} Frame Count: {file.frame_count()}\")\n",
    "    print(f\"{filename} Frame Width: {file.frame_width}\")\n",
    "    print(f\"{filename} Length in ms: {len(file)}\")\n",
    "\n",
    "showPydubStats(\"exportedWav/file1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909b2f67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mujhe kuch khane ko de do'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe Function\n",
    "#===================\n",
    "\n",
    "def transcribeAudio(filename):\n",
    "    #Setup a Recognizer Function\n",
    "    recognizer = sr.Recognizer()\n",
    "    #Import Audio Fiel and Convert it into Audio Data\n",
    "    file = sr.AudioFile(filename)\n",
    "    with file as src:\n",
    "        fileData = recognizer.record(src)\n",
    "    #Return Transcribed Text\n",
    "    return recognizer.recognize_google(fileData)\n",
    "\n",
    "transcribeAudio(\"exportedWav/file1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb0fb5",
   "metadata": {},
   "source": [
    "#  \n",
    "#   \n",
    "# Sentiment Analysis on Spoken Language Text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cf61f77",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Download Required NLTK Packages\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601bd5e",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bb1051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.349, 'pos': 0.651, 'compound': 0.6808}\n"
     ]
    }
   ],
   "source": [
    "#Import Sentiment Analysis Class\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Create Sentiment Analysis Instance\n",
    "ins = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Test Sentiment Analysis on Text\n",
    "print(ins.polarity_scores(\"I am having Great Accomplishing Feeling.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f02c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting customer1.ogg to exportedWav/customer1.wav... (completed)\n",
      "hi yeah this is paid on this call and obviously the status of my order at 3 weeks ago and that order is terrible is it any better\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.096, 'neu': 0.745, 'pos': 0.158, 'compound': 0.25}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe Customer Call\n",
    "convertToWav(\"ipFiles/customer1.ogg\")\n",
    "call = transcribeAudio(\"exportedWav/customer1.wav\")\n",
    "print(call)\n",
    "\n",
    "#Sentiment Analysis on Customer Call\n",
    "ins.polarity_scores(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ede94b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting customer2.ogg to exportedWav/customer2.wav... (completed)\n",
      "\n",
      "Transcribed Text is:\n",
      "I think I should try some other consumer services or different product and the service was my last experience was really bad like it was terrible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.225, 'neu': 0.685, 'pos': 0.091, 'compound': -0.6267}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe Customer Call\n",
    "convertToWav(\"ipFiles/customer2.ogg\")\n",
    "call = transcribeAudio(\"exportedWav/customer2.wav\")\n",
    "print(f\"\\nTranscribed Text is:\\n{call}\")\n",
    "\n",
    "#Sentiment Analysis on Customer Call\n",
    "ins.polarity_scores(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f75cc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Hi, there.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Hi, This is XYZ Customer Service.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I help you?\n",
      "{'neg': 0.0, 'neu': 0.526, 'pos': 0.474, 'compound': 0.4019}\n",
      "Hi, I ordered some products under ID Saucy.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I've been waiting for it but\n",
      "I have not gotten any update.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "It is not good to wait.\n",
      "{'neg': 0.325, 'neu': 0.675, 'pos': 0.0, 'compound': -0.3412}\n",
      "Kindly check the order status and give a proper response \n",
      "when can I get my products.\n",
      "{'neg': 0.0, 'neu': 0.802, 'pos': 0.198, 'compound': 0.4939}\n",
      "It sucks to wait.\n",
      "{'neg': 0.455, 'neu': 0.545, 'pos': 0.0, 'compound': -0.3612}\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis Sentence by Sentence\n",
    "tarnscribedText = \"\"\"Hello. Hi, there. \n",
    "Hi, This is XYZ Customer Service. How can I help you? \n",
    "Hi, I ordered some products under ID Saucy. I've been waiting for it but\n",
    "I have not gotten any update. It is not good to wait. \n",
    "Kindly check the order status and give a proper response \n",
    "when can I get my products. It sucks to wait.\"\"\"\n",
    "\n",
    "#Import Tokenize Function\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#Find Sentiment on Each Sentence\n",
    "for sentence in sent_tokenize(tarnscribedText):\n",
    "    print(sentence)\n",
    "    print(ins.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb4ad9",
   "metadata": {},
   "source": [
    "# \n",
    "#   \n",
    "# Named Entity Recognition on Transcribed Text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26ea647f",
   "metadata": {},
   "source": [
    "Commands to install spacy\n",
    "=========================\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "OR\n",
    "To install this package with conda run one of the following:\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge/label/gcc7 spacy\n",
    "conda install -c conda-forge/label/cf201901 spacy\n",
    "conda install -c conda-forge/label/cf202003 spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618fa1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#Load spaCy Language Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32f3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spaCy Document\n",
    "doc = nlp(\"I ordered a smartphone from your Islamabad store on October 28, 2021. My order number is 9876543. Yesterday, I consulted one of your customer service team, Lahore, Pakistan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd98dd82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 0\n",
      "ordered 2\n",
      "a 10\n",
      "smartphone 12\n",
      "from 23\n",
      "your 28\n",
      "Islamabad 33\n",
      "store 43\n",
      "on 49\n",
      "October 52\n",
      "28 60\n",
      ", 62\n",
      "2021 64\n",
      ". 68\n",
      "My 70\n",
      "order 73\n",
      "number 79\n",
      "is 86\n",
      "9876543 89\n",
      ". 96\n",
      "Yesterday 98\n",
      ", 107\n",
      "I 109\n",
      "consulted 111\n",
      "one 121\n",
      "of 125\n",
      "your 128\n",
      "customer 133\n",
      "service 142\n",
      "team 150\n",
      ", 154\n",
      "Lahore 156\n",
      ", 162\n",
      "Pakistan 164\n",
      ". 172\n"
     ]
    }
   ],
   "source": [
    "#Show Tokens and Indexes\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f310944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ordered a smartphone from your Islamabad store on October 28, 2021.\n",
      "My order number is 9876543.\n",
      "Yesterday, I consulted one of your customer service team, Lahore, Pakistan.\n"
     ]
    }
   ],
   "source": [
    "#Show Sentences in Doc\n",
    "\n",
    "for sentences in doc.sents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4706762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islamabad GPE\n",
      "October 28, 2021 DATE\n",
      "9876543 DATE\n",
      "Yesterday DATE\n",
      "Lahore GPE\n",
      "Pakistan GPE\n"
     ]
    }
   ],
   "source": [
    "#Getting Named Entities in doc\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204ae3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x000001D18B01BD60>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000001D18B02CA40>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x000001D18AFD02E0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000001D18B04C7C0>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000001D18B084740>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x000001D18AE1FE80>)]\n"
     ]
    }
   ],
   "source": [
    "#Import EntityRuler Class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "#spaCy Pipeline\n",
    "print(nlp.pipline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24d36cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x000001D18CAB79C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15420/3305694141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Update existing pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Check Updated Pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x000001D18CAB79C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "#Changing the Pipeline\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Update existing pipeline\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "#Check Updated Pipeline\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852620b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
