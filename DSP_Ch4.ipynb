{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c66621",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer1.ogg',\n",
       " 'customer1.wav',\n",
       " 'customer2.ogg',\n",
       " 'customer2.wav',\n",
       " 'file1.mp3',\n",
       " 'file2.flac',\n",
       " 'file3.flac',\n",
       " 'file4.flac',\n",
       " 'file5.ogg',\n",
       " 'file6.ogg',\n",
       " 'file7.ogg',\n",
       " 'file8.mp4',\n",
       " 'file9.ogg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import OS Module\n",
    "import os\n",
    "\n",
    "#Check Audio Files Folder\n",
    "os.listdir(\"ipFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae57f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mujhe kuch khane ko de do'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#Import First File and Convert to .wav\n",
    "file1 = AudioSegment.from_file(\"ipFiles/file1.mp3\")\n",
    "file1.export(\"exportedWav.file1.wav\", format=\"wav\")\n",
    "\n",
    "#Transcribe file1\n",
    "recognizer = sr.Recognizer()\n",
    "file1_file = sr.AudioFile(\"exportedWav/file1.wav\")\n",
    "with file1_file as src:\n",
    "    file1_audio = recognizer.record(file1_file)\n",
    "recognizer.recognize_google(file1_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd2599",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09839212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #File Format Conversion Function\n",
    "# #===============================\n",
    "\n",
    "# def convertToWav(filename):\n",
    "#     #Import Audio File\n",
    "#     file = AudioSegment.from_file(filename)\n",
    "#     #Create New Filename\n",
    "#     filename = filename.split(\"/\")[1] #to remove parent directory\n",
    "#     newFilename = \"exportedPre/\" + filename.split(\".\")[0] + \".wav\"\n",
    "#     #Export file as .wav\n",
    "#     file.export(newFilename, format=\"wav\")\n",
    "#     print(f\"Converting {filename} to {newFilename}... (completed)\")\n",
    "    \n",
    "# convertToWav(\"ipFiles/file1.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26eda8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting prePurchase/prePurchase1.ogg to prePurchase/prePurchase1.wav...(Completed)\n"
     ]
    }
   ],
   "source": [
    "def convertToWav(filename):\n",
    "    file = AudioSegment.from_file(filename)\n",
    "    newFilename = filename.split(\".\")[0] + \".wav\"\n",
    "    file.export(newFilename, format=\"wav\")\n",
    "    print(f\"Converting {filename} to {newFilename}...(Completed)\")\n",
    "    \n",
    "convertToWav(\"prePurchase/prePurchase1.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f7b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prePurchase/prePurchase1.wav Channels: 1\n",
      "prePurchase/prePurchase1.wav Sample Width: 4\n",
      "prePurchase/prePurchase1.wav Frame Rate: 48000\n",
      "prePurchase/prePurchase1.wav Frame Count: 173760.0\n",
      "prePurchase/prePurchase1.wav Frame Width: 4\n",
      "prePurchase/prePurchase1.wav Length in ms: 3620\n"
     ]
    }
   ],
   "source": [
    "#Attribute Showing Function\n",
    "#==========================\n",
    "\n",
    "def showPydubStats(filename):\n",
    "    #Create AudioSegment Instance\n",
    "    file = AudioSegment.from_file(filename)\n",
    "    #Print Audio Attributes\n",
    "    print(f\"{filename} Channels: {file.channels}\")\n",
    "    print(f\"{filename} Sample Width: {file.sample_width}\")\n",
    "    print(f\"{filename} Frame Rate: {file.frame_rate}\")\n",
    "    print(f\"{filename} Frame Count: {file.frame_count()}\")\n",
    "    print(f\"{filename} Frame Width: {file.frame_width}\")\n",
    "    print(f\"{filename} Length in ms: {len(file)}\")\n",
    "\n",
    "showPydubStats(\"prePurchase/prePurchase1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909b2f67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Transcribe Function\n",
    "# #===================\n",
    "\n",
    "# def transcribeAudio(filename):\n",
    "#     #Setup a Recognizer Function\n",
    "#     recognizer = sr.Recognizer()\n",
    "#     #Import Audio Fiel and Convert it into Audio Data\n",
    "#     file = sr.AudioFile(filename)\n",
    "#     with file as src:\n",
    "#         fileData = recognizer.record(src)\n",
    "#     #Return Transcribed Text\n",
    "#     return recognizer.recognize_google(fileData)\n",
    "\n",
    "# transcribeAudio(\"exportedWav/file1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14703940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I recently got this pair of shoes but they are too big can I change the size'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transcribeAudio(filename):\n",
    "    rec = sr.Recognizer()\n",
    "    file = sr.AudioFile(filename)\n",
    "    with file as src:\n",
    "        fileData = rec.record(src)\n",
    "    return rec.recognize_google(fileData)\n",
    "\n",
    "transcribeAudio(\"postPurchase/postPurchase1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb0fb5",
   "metadata": {},
   "source": [
    "#  \n",
    "#   \n",
    "# Sentiment Analysis on Spoken Language Text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb98a619",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Download Required NLTK Packages\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601bd5e",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bb1051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.349, 'pos': 0.651, 'compound': 0.6808}\n"
     ]
    }
   ],
   "source": [
    "#Import Sentiment Analysis Class\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#Create Sentiment Analysis Instance\n",
    "ins = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Test Sentiment Analysis on Text\n",
    "print(ins.polarity_scores(\"I am having Great Accomplishing Feeling.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f02c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ipFiles/customer1.ogg to ipFiles/customer1.wav...(Completed)\n",
      "hi yeah this is paid on this call and obviously the status of my order at 3 weeks ago and that order is terrible is it any better\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.096, 'neu': 0.745, 'pos': 0.158, 'compound': 0.25}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe Customer Call\n",
    "convertToWav(\"ipFiles/customer1.ogg\")\n",
    "call = transcribeAudio(\"exportedWav/customer1.wav\")\n",
    "print(call)\n",
    "\n",
    "#Sentiment Analysis on Customer Call\n",
    "ins.polarity_scores(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ede94b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ipFiles/customer2.ogg to ipFiles/customer2.wav...(Completed)\n",
      "\n",
      "Transcribed Text is:\n",
      "I think I should try some other consumer services or different product and the service was my last experience was really bad like it was terrible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.225, 'neu': 0.685, 'pos': 0.091, 'compound': -0.6267}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe Customer Call\n",
    "convertToWav(\"ipFiles/customer2.ogg\")\n",
    "call = transcribeAudio(\"exportedWav/customer2.wav\")\n",
    "print(f\"\\nTranscribed Text is:\\n{call}\")\n",
    "\n",
    "#Sentiment Analysis on Customer Call\n",
    "ins.polarity_scores(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f75cc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Hi, there.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Hi, This is XYZ Customer Service.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I help you?\n",
      "{'neg': 0.0, 'neu': 0.526, 'pos': 0.474, 'compound': 0.4019}\n",
      "Hi, I ordered some products under ID Saucy.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I've been waiting for it but\n",
      "I have not gotten any update.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "It is not good to wait.\n",
      "{'neg': 0.325, 'neu': 0.675, 'pos': 0.0, 'compound': -0.3412}\n",
      "Kindly check the order status and give a proper response \n",
      "when can I get my products.\n",
      "{'neg': 0.0, 'neu': 0.802, 'pos': 0.198, 'compound': 0.4939}\n",
      "It sucks to wait.\n",
      "{'neg': 0.455, 'neu': 0.545, 'pos': 0.0, 'compound': -0.3612}\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis Sentence by Sentence\n",
    "tarnscribedText = \"\"\"Hello. Hi, there. \n",
    "Hi, This is XYZ Customer Service. How can I help you? \n",
    "Hi, I ordered some products under ID Saucy. I've been waiting for it but\n",
    "I have not gotten any update. It is not good to wait. \n",
    "Kindly check the order status and give a proper response \n",
    "when can I get my products. It sucks to wait.\"\"\"\n",
    "\n",
    "#Import Tokenize Function\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#Find Sentiment on Each Sentence\n",
    "for sentence in sent_tokenize(tarnscribedText):\n",
    "    print(sentence)\n",
    "    print(ins.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb4ad9",
   "metadata": {},
   "source": [
    "# \n",
    "#   \n",
    "# Named Entity Recognition on Transcribed Text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26ea647f",
   "metadata": {},
   "source": [
    "Commands to install spacy\n",
    "=========================\n",
    "pip install -U pip setuptools wheel\n",
    "pip install -U spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "OR\n",
    "To install this package with conda run one of the following:\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge/label/gcc7 spacy\n",
    "conda install -c conda-forge/label/cf201901 spacy\n",
    "conda install -c conda-forge/label/cf202003 spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "618fa1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#Load spaCy Language Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32f3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spaCy Document\n",
    "doc = nlp(\"I ordered a smartphone from your Islamabad store on October 28, 2021. My order number is 9876543. Yesterday, I consulted one of your customer service team, Lahore, Pakistan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd98dd82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 0\n",
      "ordered 2\n",
      "a 10\n",
      "smartphone 12\n",
      "from 23\n",
      "your 28\n",
      "Islamabad 33\n",
      "store 43\n",
      "on 49\n",
      "October 52\n",
      "28 60\n",
      ", 62\n",
      "2021 64\n",
      ". 68\n",
      "My 70\n",
      "order 73\n",
      "number 79\n",
      "is 86\n",
      "9876543 89\n",
      ". 96\n",
      "Yesterday 98\n",
      ", 107\n",
      "I 109\n",
      "consulted 111\n",
      "one 121\n",
      "of 125\n",
      "your 128\n",
      "customer 133\n",
      "service 142\n",
      "team 150\n",
      ", 154\n",
      "Lahore 156\n",
      ", 162\n",
      "Pakistan 164\n",
      ". 172\n"
     ]
    }
   ],
   "source": [
    "#Show Tokens and Indexes\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f310944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ordered a smartphone from your Islamabad store on October 28, 2021.\n",
      "My order number is 9876543.\n",
      "Yesterday, I consulted one of your customer service team, Lahore, Pakistan.\n"
     ]
    }
   ],
   "source": [
    "#Show Sentences in Doc\n",
    "\n",
    "for sentences in doc.sents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4706762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islamabad GPE\n",
      "October 28, 2021 DATE\n",
      "9876543 DATE\n",
      "Yesterday DATE\n",
      "Lahore GPE\n",
      "Pakistan GPE\n"
     ]
    }
   ],
   "source": [
    "#Getting Named Entities in doc\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "204ae3f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x0000018C51A38770>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x0000018C51A482C0>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x0000018C519E27C0>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x0000018C51A64A00>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x0000018C51A92C00>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x0000018C51846EE0>)]\n"
     ]
    }
   ],
   "source": [
    "#Import EntityRuler Class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "#spaCy Pipeline\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d36cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x18c51a38770>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x18c51a482c0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x18c519e27c0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x18c51a64a00>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x18c51a92c00>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x18c51846ee0>),\n",
       " ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler at 0x18c51782780>)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create the EntityRuler\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", after=\"ner\")\n",
    "\n",
    "#List of Entities and Patterns\n",
    "patterns = [{\"label\": \"PRODUCT\",\n",
    "             \"pattern\": \"smartphone\"}]\n",
    "\n",
    "#Add patterns in ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "#Check Updated Pipeline\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a66b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smartphone PRODUCT\n",
      "Islamabad GPE\n",
      "October 28, 2021 DATE\n",
      "9876543 DATE\n",
      "Yesterday DATE\n",
      "Lahore GPE\n",
      "Pakistan GPE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pattern = [{\"label\": \"PRODUCT\", \"pattern\": \"SMARTPHONE\"}]\n",
    "# ruler.add_patterns(pattern)\n",
    "\n",
    "# doc = nlp(\"I ordered a smartphone from your Islamabad store on October 28, 2021. My order number is 9876543. Yesterday, I consulted one of your customer service team, Lahore, Pakistan.\")\n",
    "# for ent in doc.ents:\n",
    "#     print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e63ccd25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smartphone PRODUCT\n",
      "Islamabad GPE\n",
      "October 28, 2021 DATE\n",
      "9876543 DATE\n",
      "Yesterday DATE\n",
      "Lahore GPE\n",
      "Pakistan GPE\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd57afe",
   "metadata": {},
   "source": [
    "# \n",
    "#   \n",
    "# Classifying Transcribed Speech with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a10909e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prePurchase1.ogg', 'prePurchase2.ogg', 'prePurchase3.ogg']\n"
     ]
    }
   ],
   "source": [
    "#Inspect Pre Purchase Audio Folder\n",
    "prePurchase = os.listdir(\"prePurchase\")\n",
    "print(prePurchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933ada80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting prePurchase1.ogg to .wav...\n",
      "Converting prePurchase/prePurchase1.ogg to prePurchase/prePurchase1.wav...(Completed)\n",
      "Converting prePurchase2.ogg to .wav...\n",
      "Converting prePurchase/prePurchase2.ogg to prePurchase/prePurchase2.wav...(Completed)\n",
      "Converting prePurchase3.ogg to .wav...\n",
      "Converting prePurchase/prePurchase3.ogg to prePurchase/prePurchase3.wav...(Completed)\n"
     ]
    }
   ],
   "source": [
    "#Loop through ogg files in prePurchase Folder\n",
    "for file in prePurchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    #Use Helper Function to Convert to wav Format\n",
    "    convertToWav(\"prePurchase/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8796d358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def createTextList(folder):\n",
    "#     textList = []\n",
    "#     #Loop through folder\n",
    "#     for file in folder:\n",
    "#         #Check for .wav extension\n",
    "#         if file.endswith(\".wav\"):\n",
    "#             #Transcribe Audio Helper Function\n",
    "#             text = transcribeAudio(folder+\"/\"+file))\n",
    "#             textList.append(text)\n",
    "#         return textList\n",
    "\n",
    "\n",
    "# #Convert Pre-PurchaseAudio to Text\n",
    "# prePurchaseText = createTextList(\"prePurchase\")\n",
    "# print(prePurchaseText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff8247e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "textList = []\n",
    "for file in prePurchase:\n",
    "    if file.endswith(\".wav\"):\n",
    "        text = (transcribeAudio(\"prePurchase/\"+file))\n",
    "#         print(text)\n",
    "        textList.append(text)\n",
    "prePurchaseText = textList\n",
    "print(prePurchaseText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae89e231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['would you kindly inform me if you are dealing with product customisation', 'is there any colour priority in this pants', 'hi man how long will the delivery take I need the product in agency']\n"
     ]
    }
   ],
   "source": [
    "prePurchase = os.listdir(\"prePurchase\")\n",
    "textList = []\n",
    "for file in prePurchase:\n",
    "    if file.endswith(\".wav\"):\n",
    "        text = (transcribeAudio(\"prePurchase/\"+file))\n",
    "#         print(text)\n",
    "        textList.append(text)\n",
    "prePurchaseText = textList\n",
    "print(prePurchaseText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8765f51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['postPurchase1.ogg', 'postPurchase2.ogg', 'postPurchase3.ogg']\n",
      "Converting postPurchase1.ogg to .wav...\n",
      "Converting postPurchase/postPurchase1.ogg to postPurchase/postPurchase1.wav...(Completed)\n",
      "Converting postPurchase2.ogg to .wav...\n",
      "Converting postPurchase/postPurchase2.ogg to postPurchase/postPurchase2.wav...(Completed)\n",
      "Converting postPurchase3.ogg to .wav...\n",
      "Converting postPurchase/postPurchase3.ogg to postPurchase/postPurchase3.wav...(Completed)\n"
     ]
    }
   ],
   "source": [
    "#Inspect Pre Purchase Audio Folder\n",
    "postPurchase = os.listdir(\"postPurchase\")\n",
    "print(postPurchase)\n",
    "\n",
    "#Loop through ogg files in prePurchase Folder\n",
    "for file in postPurchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    #Use Helper Function to Convert to wav Format\n",
    "    convertToWav(\"postPurchase/\"+file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2524fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I recently got this pair of shoes but they are too big can I change the size', 'I bought a pair of pants from you guys but they are way too small', 'about a pair of pants and their the wrong colour so is there any chance I can change the colour or I can change the order or replay fat']\n"
     ]
    }
   ],
   "source": [
    "#Transcribe postPurchase Files\n",
    "postPurchase = os.listdir(\"postPurchase\")\n",
    "textList = []\n",
    "for file in postPurchase:\n",
    "    if file.endswith(\".wav\"):\n",
    "        text = (transcribeAudio(\"postPurchase/\"+file))\n",
    "#         print(text)\n",
    "        textList.append(text)\n",
    "postPurchaseText = textList\n",
    "print(postPurchaseText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7a426d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prePurchase</td>\n",
       "      <td>would you kindly inform me if you are dealing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prePurchase</td>\n",
       "      <td>is there any colour priority in this pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prePurchase</td>\n",
       "      <td>hi man how long will the delivery take I need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>postPurchase</td>\n",
       "      <td>I recently got this pair of shoes but they are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>postPurchase</td>\n",
       "      <td>I bought a pair of pants from you guys but the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "0   prePurchase  would you kindly inform me if you are dealing ...\n",
       "1   prePurchase         is there any colour priority in this pants\n",
       "2   prePurchase  hi man how long will the delivery take I need ...\n",
       "0  postPurchase  I recently got this pair of shoes but they are...\n",
       "1  postPurchase  I bought a pair of pants from you guys but the..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Organizing Trascirbed Data\n",
    "import pandas as pd\n",
    "#Create prePurchase dataframe\n",
    "prePurchaseDF = pd.DataFrame({\"label\": \"prePurchase\",\n",
    "                             \"text\": prePurchaseText})\n",
    "postPurchaseDF = pd.DataFrame({\"label\": \"postPurchase\",\n",
    "                             \"text\": postPurchaseText})\n",
    "\n",
    "#Combining prePurchase and postPurchase\n",
    "df = pd.concat([prePurchaseDF, postPurchaseDF])\n",
    "\n",
    "#View Combine dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8777b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Text Classifier\n",
    "#========================\n",
    "\n",
    "#Import Text Classification Packages\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bdde609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data into Train and Test Sets\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x=df[\"text\"],\n",
    "#                                                     y=df[\"label\"],\n",
    "#                                                     test_size=0.3)\n",
    "# Splitting the Dataset into the training set and the test set\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68031e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes Pipeline\n",
    "textClassifier = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "#Fit the Classifier Pipeline on the Training Data\n",
    "textClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d17d9db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model is  100.00% accurate.\n"
     ]
    }
   ],
   "source": [
    "#Make Prediction and Compare them to Text Labels\n",
    "predictions = textClassifier.predict(X_test)\n",
    "accuracy = 100 * np.mean(predictions == y_test)\n",
    "print(f\"The Model is {accuracy: .2f}% accurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896fd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
