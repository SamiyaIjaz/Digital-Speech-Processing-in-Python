{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde4e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing SpeechRecognition Library \n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db98d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Recognizer Class Instance\n",
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15260198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Energy Threshold\n",
    "recognizer.energy_threshold = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a18680",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "``audio_data`` must be audio data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-422fe01b2fe0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Use Google Recognizer Class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sample/helpCall.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"en-US\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0mRaises\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mspeech_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnknownValueError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspeech\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0munintelligible\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mRaises\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mspeech_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0mrecognition\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mno\u001b[0m \u001b[0minternet\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudioData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``audio_data`` must be audio data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``key`` must be ``None`` or a string\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"``language`` must be a string\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ``audio_data`` must be audio data"
     ]
    }
   ],
   "source": [
    "#Use Google Recognizer Class\n",
    "recognizer.recognize_google(audio_data=\"sample/helpCall.wav\", language=\"en-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1bd5b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioFile"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Audio File\n",
    "helpCall_file = sr.AudioFile(\"sample/helpCall.wav\")\n",
    "#Check the Type of Variable\n",
    "type(helpCall_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b793f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert AudioFile to AudioData\n",
    "with helpCall_file as source:\n",
    "    #record the audio\n",
    "    helpCall_audio = recognizer.record(source)\n",
    "#Check Type\n",
    "type(helpCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395343da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello I want to get some help setting up my time please'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.recognize_google(audio_data=helpCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86fafea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello I want to get some help setting up my time please'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leaving offset and duration as default\n",
    "with helpCall_file as src:\n",
    "    helpCall_audio = recognizer.record(src,\n",
    "                                      duration = None,\n",
    "                                      offset = None)\n",
    "#Transcribing helpCall_audio\n",
    "recognizer.recognize_google(audio_data=helpCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3198a67c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing Duration\n",
    "with helpCall_file as src:\n",
    "    helpCall_audio = recognizer.record(src,\n",
    "                                      duration = 2.0,\n",
    "                                      offset = None)\n",
    "#Transcribing helpCall_audio\n",
    "recognizer.recognize_google(audio_data=helpCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b29bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setting up my cam please'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing Duration\n",
    "with helpCall_file as src:\n",
    "    helpCall_audio = recognizer.record(src,\n",
    "                                      offset = 2.0)\n",
    "#Transcribing helpCall_audio\n",
    "recognizer.recognize_google(audio_data=helpCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172bb820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urdu Speech AudioFile:\n",
      " <class 'speech_recognition.AudioFile'>\n",
      "Urdu Speech AudioData:\n",
      " <class 'speech_recognition.AudioData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mujhe kuch khane ko de do'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Urdu Speech in English Language\n",
    "#==============================================\n",
    "\n",
    "#Read Audio File\n",
    "urduSpeech_file = sr.AudioFile(\"sample/urduSpeech.wav\")\n",
    "#Check the Type of Variable\n",
    "print(f\"Urdu Speech AudioFile:\\n {type(urduSpeech_file)}\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with urduSpeech_file as source:\n",
    "    #record the audio\n",
    "    urduSpeech_audio = recognizer.record(source)\n",
    "#Check Type\n",
    "print(f\"Urdu Speech AudioData:\\n {type(urduSpeech_audio)}\")\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=urduSpeech_audio, language=\"en-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a4d82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urdu Speech AudioFile:\n",
      " <class 'speech_recognition.AudioFile'>\n",
      "Urdu Speech AudioData:\n",
      " <class 'speech_recognition.AudioData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'مجھے کچھ کھانے کو دے دو'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Urdu Speech in Urdu Language\n",
    "#==============================================\n",
    "\n",
    "#Read Audio File\n",
    "urduSpeech_file = sr.AudioFile(\"sample/urduSpeech.wav\")\n",
    "#Check the Type of Variable\n",
    "print(f\"Urdu Speech AudioFile:\\n {type(urduSpeech_file)}\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with urduSpeech_file as source:\n",
    "    #record the audio\n",
    "    urduSpeech_audio = recognizer.record(source)\n",
    "#Check Type\n",
    "print(f\"Urdu Speech AudioData:\\n {type(urduSpeech_audio)}\")\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=urduSpeech_audio, language=\"ur-PK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc36fe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roar AudioFile:\n",
      " <class 'speech_recognition.AudioFile'>\n",
      "Roar AudioData:\n",
      " <class 'speech_recognition.AudioData'>\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-69b24b133884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Transcribing urduSpeech_audio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroar_audio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;31m# return results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_all\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"confidence\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Transcribing Non-Speech Audio\n",
    "#=============================\n",
    "\n",
    "#Read Audio File\n",
    "roar_file = sr.AudioFile(\"sample/roar.wav\")\n",
    "#Check the Type of Variable\n",
    "print(f\"Roar AudioFile:\\n {type(roar_file)}\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with roar_file as source:\n",
    "    #record the audio\n",
    "    roar_audio = recognizer.record(source)\n",
    "#Check Type\n",
    "print(f\"Roar AudioData:\\n {type(roar_audio)}\")\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=roar_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00db4848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roar AudioFile:\n",
      " <class 'speech_recognition.AudioFile'>\n",
      "Roar AudioData:\n",
      " <class 'speech_recognition.AudioData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Non-Speech Audio\n",
    "#=============================\n",
    "\n",
    "#Read Audio File\n",
    "roar_file = sr.AudioFile(\"sample/roar.wav\")\n",
    "#Check the Type of Variable\n",
    "print(f\"Roar AudioFile:\\n {type(roar_file)}\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with roar_file as source:\n",
    "    #record the audio\n",
    "    roar_audio = recognizer.record(source)\n",
    "#Check Type\n",
    "print(f\"Roar AudioData:\\n {type(roar_audio)}\")\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=roar_audio, show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ad0fa76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternative': [{'transcript': 'mujhe kuch khane ko de do',\n",
       "   'confidence': 0.87336582},\n",
       "  {'transcript': 'mujhe kuchh khane ko de do'},\n",
       "  {'transcript': 'muje Kuchh khane ko de do'},\n",
       "  {'transcript': 'muje kuch khane ko de do'},\n",
       "  {'transcript': 'Tujhe Kuchh khane ko de do'}],\n",
       " 'final': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Urdu Speech in English using show_all parameter\n",
    "#============================================================\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=urduSpeech_audio,\n",
    "                            language=\"en-US\",\n",
    "                            show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4d28eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alternative': [{'transcript': 'مجھے کچھ کھانے کو دے دو',\n",
       "   'confidence': 0.89260834},\n",
       "  {'transcript': 'مجھے کچھ کھانے کو دے دوں'},\n",
       "  {'transcript': 'مجھے کچھ کچھ کھانے کو دے دو'},\n",
       "  {'transcript': 'مجھے کچھ کھانے کو دے دو و'},\n",
       "  {'transcript': 'مجھے کچھ کھانے کو دے دوں گا'}],\n",
       " 'final': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Urdu Speech in Urdu using show_all parameter\n",
    "#============================================================\n",
    "\n",
    "#Recognize Urdu AudioData with show_all turned on\n",
    "recognizer.recognize_google(audio_data=urduSpeech_audio,\n",
    "                            language=\"ur-PK\",\n",
    "                            show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84fb1da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'limitations of the speech recognition library different speakers am voices was one property tax'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing Multiple Speaker Audio\n",
    "#====================================\n",
    "\n",
    "#Read Audio File\n",
    "multiSpeaker_file = sr.AudioFile(\"sample/multiSpeaker.wav\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with multiSpeaker_file as source:\n",
    "    #record the audio\n",
    "    multiSpeaker_audio = recognizer.record(source)\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=multiSpeaker_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "707b5153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aapane Aana Tha Aaye Nahin aap log'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing sample Urdu Audio\n",
    "#====================================\n",
    "\n",
    "#Read Audio File\n",
    "sample_file = sr.AudioFile(\"sample/sample.wav\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with sample_file as source:\n",
    "    #record the audio\n",
    "    sample_audio = recognizer.record(source)\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=sample_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a747e97e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'آپ نے آنا تھا یا نہیں آپ لوگ'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing sample Urdu Audio\n",
    "#====================================\n",
    "\n",
    "#Read Audio File\n",
    "sample_file = sr.AudioFile(\"sample/sample.wav\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with sample_file as source:\n",
    "    #record the audio\n",
    "    sample_audio = recognizer.record(source)\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=sample_audio, language=\"ur-PK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03aab7ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello Assalam Walekum Nahin chalo theek hai'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing twoWay Audio\n",
    "#=============================\n",
    "\n",
    "#Read Audio File\n",
    "twoWay_file = sr.AudioFile(\"sample/twoWay.wav\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with twoWay_file as source:\n",
    "    #record the audio\n",
    "    twoWay_audio = recognizer.record(source)\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=twoWay_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e783ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bolo kya baat hai'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribing twoWay Audio\n",
    "#=============================\n",
    "\n",
    "#Read Audio File\n",
    "twoWay_file = sr.AudioFile(\"sample/twoWay.wav\")\n",
    "\n",
    "#Convert AudioFile to AudioData\n",
    "with twoWay_file as source:\n",
    "    #record the audio\n",
    "    twoWay_audio = recognizer.record(source, offset=20.0)\n",
    "\n",
    "#Transcribing urduSpeech_audio\n",
    "recognizer.recognize_google(audio_data=twoWay_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f08621b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from speaker 0:\n",
      "chatting talking cell paya jata hai\n",
      "Text from speaker 1:\n",
      "new style is not answering please try later after applying with numbers in Java\n",
      "Text from speaker 2:\n",
      "sanvali kam\n"
     ]
    }
   ],
   "source": [
    "# Multiple Speakers - Different Audio Files\n",
    "speakers = [sr.AudioFile(\"sample/speaker1.wav\"), \n",
    "            sr.AudioFile(\"sample/speaker2.wav\"), \n",
    "            sr.AudioFile(\"sample/speaker3.wav\")]\n",
    "\n",
    "# Transcribe each speaker individually\n",
    "for i, speaker in enumerate(speakers):\n",
    "    with speaker as source:\n",
    "        speaker_audio = recognizer.record(source)\n",
    "    print(f\"Text from speaker {i}:\")\n",
    "    print(recognizer.recognize_google(speaker_audio,language=\"en-US\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa0aa776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from speaker 0:\n",
      "cancel paya jata hai\n",
      "Text from speaker 1:\n",
      "new style is not answering please try later after milavat number ji Jawab Nahin\n",
      "Text from speaker 2:\n",
      "sound ringtone\n"
     ]
    }
   ],
   "source": [
    "# Multiple Speakers - Different Audio Files\n",
    "speakers = [sr.AudioFile(\"sample/speaker1.wav\"), \n",
    "            sr.AudioFile(\"sample/speaker2.wav\"), \n",
    "            sr.AudioFile(\"sample/speaker3.wav\")]\n",
    "\n",
    "# Transcribe each speaker individually\n",
    "for i, speaker in enumerate(speakers):\n",
    "    with speaker as source:\n",
    "        speaker_audio = recognizer.record(source, offset=10.0)\n",
    "    print(f\"Text from speaker {i}:\")\n",
    "    print(recognizer.recognize_google(speaker_audio,language=\"en-US\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea5f911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yaar main aapko Kabhi tha ki yah product hai vah cal Tak chahie'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple Speakers - Different Audio Files - each recording separately\n",
    "\n",
    "speaker1_file = sr.AudioFile(\"sample/speaker1.wav\")\n",
    "with speaker1_file as source:\n",
    "    speaker1_audio = recognizer.record(source, offset=17.0)\n",
    "recognizer.recognize_google(audio_data=speaker1_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "362f0e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new style is not answering please try later after 100 number se jawab motion Nahi'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "speaker2_file = sr.AudioFile(\"sample/speaker2.wav\")\n",
    "with speaker2_file as source:\n",
    "    speaker2_audio = recognizer.record(source, offset=17.0)\n",
    "recognizer.recognize_google(audio_data=speaker2_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb54c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sound ringtone'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "speaker3_file = sr.AudioFile(\"sample/speaker3.wav\")\n",
    "with speaker3_file as source:\n",
    "    speaker3_audio = recognizer.record(source, offset=10.0)\n",
    "recognizer.recognize_google(audio_data=speaker3_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c168dff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello I like to get some help with my device please I think it's a warranty I want to use it\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transcribe a Noisy Audio File\n",
    "noisyCall_file = sr.AudioFile(\"sample/noisyCall.wav\")\n",
    "with noisyCall_file as source:\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "    noisyCall_audio = recognizer.record(source)\n",
    "recognizer.recognize_google(audio_data=noisyCall_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7880d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
